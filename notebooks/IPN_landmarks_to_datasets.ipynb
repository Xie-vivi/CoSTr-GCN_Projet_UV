{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Liens utiles**\n",
        "\n",
        "## Liens officiels IPN database :\n",
        "\n",
        "\n",
        "*   Site web officiel : https://gibranbenitez.github.io/IPN_Hand/\n",
        "*   Dossier Google Drive général : https://drive.google.com/drive/folders/1aL645mUzzAvoTMwJKrbtQiNiDVJZ2EsA\n",
        "*   Dossier Google Drive vidéos : https://drive.google.com/drive/folders/1O4Fn_jbAEcKIksXHmQIMcHTyaDw4wt9x\n",
        "*   Fichier annotations pour l'entrainement : https://drive.google.com/file/d/1Y6yIcckNonsRZmyD833oCLF-ndu3rvT7\n",
        "*   Fichier annotations pour le test : https://drive.google.com/file/d/13fXL1r62yuVDn6P-QR7GYM4L7d5IdrZa\n",
        "\n",
        "\n",
        "## Liens des résultats des travaux sur IPN :\n",
        "\n",
        "\n",
        "\n",
        "*   Dossier Google Drive général : https://drive.google.com/drive/folders/1iNQrCp5XM-SmbThc52NASfIacgMJkxml\n",
        "*   Dossier Google Drive landmarks : https://drive.google.com/drive/folders/1DP1tUXELlu-RrKeVJsHx7KVdkl7x3WpI\n",
        "*   Dossier Google Drive vidéos annotées : https://drive.google.com/drive/folders/1p682ZGJV6MpPsZl8yRFHwfQjcKkbvbkB\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sAWaEoSYj2Xk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Téléchargement des fichiers**"
      ],
      "metadata": {
        "id": "EmQtHGFlV83x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf sample_data\n",
        "!pip install -q --upgrade --no-cache-dir gdown\n",
        "\n",
        "# Landmarks\n",
        "!gdown --folder https://drive.google.com/drive/folders/1p682ZGJV6MpPsZl8yRFHwfQjcKkbvbkB\n",
        "\n",
        "# Annotations\n",
        "!gdown https://drive.google.com/uc?id=1Y6yIcckNonsRZmyD833oCLF-ndu3rvT7 -O Annot_TrainList.txt\n",
        "!gdown https://drive.google.com/uc?id=13fXL1r62yuVDn6P-QR7GYM4L7d5IdrZa -O Annot_TestList.txt"
      ],
      "metadata": {
        "id": "WIjl-Fm2ol2R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9b05cf8-ad53-41f9-c35c-6dd7d0a08246"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving folder list\n",
            "Processing file 1g0NiXJEibAZdW4W4QAD9_IgCQsZeZ_a5 videos01_txt.tgz\n",
            "Processing file 1JVuTLp5di33ofDp4njsFhOBPTj8_sZwo videos02_txt.tgz\n",
            "Processing file 1bR5sBDBlrWCaiVxS8Z7OHACsUVPFo36C videos03_txt.tgz\n",
            "Processing file 12XQrgHFtRx8Vm3_DIG2vdhjA1OAkSHB0 videos04_txt.tgz\n",
            "Processing file 1BqQRYWQ2Koz20Zjy9MvDk0K7g--wpSCH videos05_txt.tgz\n",
            "Retrieving folder list completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1g0NiXJEibAZdW4W4QAD9_IgCQsZeZ_a5\n",
            "To: /content/videos_txt/videos01_txt.tgz\n",
            "100% 81.1M/81.1M [00:00<00:00, 108MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JVuTLp5di33ofDp4njsFhOBPTj8_sZwo\n",
            "To: /content/videos_txt/videos02_txt.tgz\n",
            "100% 84.0M/84.0M [00:00<00:00, 125MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1bR5sBDBlrWCaiVxS8Z7OHACsUVPFo36C\n",
            "To: /content/videos_txt/videos03_txt.tgz\n",
            "100% 87.5M/87.5M [00:00<00:00, 109MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12XQrgHFtRx8Vm3_DIG2vdhjA1OAkSHB0\n",
            "To: /content/videos_txt/videos04_txt.tgz\n",
            "100% 72.4M/72.4M [00:00<00:00, 149MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BqQRYWQ2Koz20Zjy9MvDk0K7g--wpSCH\n",
            "To: /content/videos_txt/videos05_txt.tgz\n",
            "100% 77.5M/77.5M [00:00<00:00, 142MB/s]\n",
            "Download completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Y6yIcckNonsRZmyD833oCLF-ndu3rvT7\n",
            "To: /content/Annot_TrainList.txt\n",
            "100% 137k/137k [00:00<00:00, 28.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=13fXL1r62yuVDn6P-QR7GYM4L7d5IdrZa\n",
            "To: /content/Annot_TestList.txt\n",
            "100% 54.7k/54.7k [00:00<00:00, 63.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extraction des fichiers compressés**"
      ],
      "metadata": {
        "id": "XmffPMWZYmKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tarfile\n",
        "\n",
        "def extract_compressed_files_in_folder(compressed_files_folder_path, output_folder_path):\n",
        "  for file in os.listdir(compressed_files_folder_path):\n",
        "    with tarfile.open(compressed_files_folder_path + \"/\" + file) as tar_file:\n",
        "      tar_file.extractall(output_folder_path)"
      ],
      "metadata": {
        "id": "hZJHZy2lkY2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_compressed_files_in_folder(\"/content/videos_txt\", \"/content/videos\")"
      ],
      "metadata": {
        "id": "rYsQAq3hLRmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Constantes**"
      ],
      "metadata": {
        "id": "KMtYngKRLpYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LANDMARKS_NUMBER = 21\n",
        "LANDMARK_DIMENSION = 3\n",
        "\n",
        "# Ordre des infos des annotations\n",
        "VIDEO_NAME_PLACE = 0\n",
        "GESTURE_NAME_PLACE = 1\n",
        "GESTURE_ID_PLACE = 2\n",
        "T_START_PLACE = 3\n",
        "T_END_PLACE = 4\n",
        "GESTURE_LENGTH_PLACE = 5"
      ],
      "metadata": {
        "id": "Ak5GPhsgLo1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Création des datasets**"
      ],
      "metadata": {
        "id": "Dq0CHJhiKFwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def remove_newline(strings):\n",
        "  return [string.replace('\\n', '') for string in strings]\n",
        "\n",
        "def read_txt_file(txt_file_path):\n",
        "  with open(txt_file_path) as annot_file:\n",
        "    return remove_newline(annot_file.readlines())\n",
        "\n",
        "def extract_landmarks(line):\n",
        "  res = np.zeros((LANDMARKS_NUMBER, LANDMARK_DIMENSION))\n",
        "  if line != ';':\n",
        "    split_line = line.split(';')\n",
        "    for landmark in range(LANDMARKS_NUMBER):\n",
        "      for dimension in range(LANDMARK_DIMENSION):\n",
        "        res[landmark][dimension] = float(split_line[landmark*3 + dimension])\n",
        "  return res"
      ],
      "metadata": {
        "id": "IzORhyHyh9Cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_videos_number(annotations):\n",
        "  count = 0\n",
        "  current_video_name = \"\"\n",
        "  for info in annotations:\n",
        "    video_name = info.split(',')[VIDEO_NAME_PLACE]\n",
        "    if current_video_name != video_name:\n",
        "      current_video_name = video_name\n",
        "      count += 1\n",
        "  return count\n",
        "\n",
        "def get_maximum_length_gestures(annotations):\n",
        "  maximum_length = 0\n",
        "  for info in annotations:\n",
        "    gesture_length = int(info.split(',')[GESTURE_LENGTH_PLACE])\n",
        "    if gesture_length > maximum_length:\n",
        "      maximum_length = gesture_length\n",
        "  return maximum_length\n",
        "\n",
        "def get_maximum_length_videos(annotations):\n",
        "  maximum_length = 0\n",
        "  for info in annotations:\n",
        "    t_end = int(info.split(',')[T_END_PLACE])\n",
        "    if t_end > maximum_length:\n",
        "      maximum_length = t_end\n",
        "  return maximum_length"
      ],
      "metadata": {
        "id": "XxQXjCxVCyDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_segmented_dataset(annotations_file_path, print_task_progress=True):\n",
        "  # Lecture des annotations\n",
        "  annotations = read_txt_file(annotations_file_path)\n",
        "  gestures_number = len(annotations)\n",
        "  maximum_length_gestures = get_maximum_length_gestures(annotations)\n",
        "\n",
        "  # Initilisation des shapes des résultats\n",
        "  X = np.zeros((gestures_number, maximum_length_gestures, LANDMARKS_NUMBER, LANDMARK_DIMENSION))\n",
        "  y = np.zeros(gestures_number)\n",
        "\n",
        "  # Vidéo actuelle pour éviter de relire le fichier entier à chaque geste de la même vidéo\n",
        "  current_video_name = \"\"\n",
        "  frames = []\n",
        "  current_video_frames_nb = 0\n",
        "\n",
        "  for gesture, info in enumerate(annotations):\n",
        "    # Affichage de l'avancement\n",
        "    if print_task_progress:\n",
        "      print(\"\\r\", end='')\n",
        "      print(\"\\rCréation du dataset segmenté - \" + \"%.2f\" % ((gesture + 1) / gestures_number * 100) + \" %\", end='')\n",
        "\n",
        "    # Extraction des infos du geste\n",
        "    video_name = info.split(',')[VIDEO_NAME_PLACE]\n",
        "    gesture_id = int(info.split(',')[GESTURE_ID_PLACE]) - 1\n",
        "    t_start = int(info.split(',')[T_START_PLACE]) - 1\n",
        "    t_end = int(info.split(',')[T_END_PLACE])\n",
        "\n",
        "    # Changement de la vidéo ?\n",
        "    if current_video_name != video_name:\n",
        "      current_video_name = video_name\n",
        "      current_video_frames = read_txt_file(\"/content/videos/\" + video_name + \".txt\")\n",
        "      current_video_frames_nb = len(current_video_frames)\n",
        "\n",
        "    # Mise à jour de X avec les coordoonées du geste\n",
        "    for frame in range(t_start, t_end):\n",
        "      if frame < current_video_frames_nb:\n",
        "        landmarks = extract_landmarks(current_video_frames[frame])\n",
        "        for landmark in range(LANDMARKS_NUMBER):\n",
        "          for dimension in range(LANDMARK_DIMENSION):\n",
        "            X[gesture][frame - t_start][landmark][dimension] = landmarks[landmark][dimension]\n",
        "    \n",
        "    # Mise à jour de y avec l'id du geste\n",
        "    y[gesture] = gesture_id\n",
        "  \n",
        "  # Affichage des shapes des résultats\n",
        "  print(\"\\rDataset segmenté - \" + annotations_file_path)\n",
        "  print(\"Shape X :\", X.shape)\n",
        "  print(\"Shape y :\", y.shape, \"\\n\")\n",
        "  \n",
        "  return X, y"
      ],
      "metadata": {
        "id": "1ncyInWVYr3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_continuous_dataset(annotations_file_path, print_task_progress=True):\n",
        "  # Lecture des annotations\n",
        "  annotations = read_txt_file(annotations_file_path)\n",
        "  gestures_number = len(annotations)\n",
        "  videos_number = get_videos_number(annotations)\n",
        "  maximum_length_videos = get_maximum_length_videos(annotations)\n",
        "\n",
        "  # Initilisation des shapes des résultats\n",
        "  X = np.zeros((videos_number, maximum_length_videos, LANDMARKS_NUMBER, LANDMARK_DIMENSION))\n",
        "  y = np.empty((0, 4), dtype=np.int64) # 4 = (numéro de la vidéo, id du geste, début du geste, fin du geste)\n",
        "\n",
        "  # Vidéo actuelle pour éviter de relire le fichier entier à chaque geste de la même vidéo\n",
        "  current_video_name = \"\"\n",
        "  frames = []\n",
        "  current_video_frames_nb = 0\n",
        "  video_id = -1\n",
        "\n",
        "  for gesture, info in enumerate(annotations):\n",
        "    # Affichage de l'avancement\n",
        "    if print_task_progress:\n",
        "      print(\"\\r\", end='')\n",
        "      print(\"\\rCréation du dataset continu - \" + \"%.2f\" % ((gesture + 1) / gestures_number * 100) + \" %\", end='')\n",
        "\n",
        "    # Extraction des infos du geste\n",
        "    video_name = info.split(',')[VIDEO_NAME_PLACE]\n",
        "    gesture_id = int(info.split(',')[GESTURE_ID_PLACE]) - 1\n",
        "    t_start = int(info.split(',')[T_START_PLACE]) - 1\n",
        "    t_end = int(info.split(',')[T_END_PLACE])\n",
        "\n",
        "    # Changement de la vidéo\n",
        "    if current_video_name != video_name:\n",
        "      current_video_name = video_name\n",
        "      current_video_frames = read_txt_file(\"/content/videos/\" + video_name + \".txt\")\n",
        "      current_video_frames_nb = len(current_video_frames)\n",
        "      video_id += 1\n",
        "\n",
        "    # Mise à jour de X avec les coordoonées du geste\n",
        "    for frame in range(t_start, t_end):\n",
        "      if frame < current_video_frames_nb:\n",
        "        landmarks = extract_landmarks(current_video_frames[frame])\n",
        "        for landmark in range(LANDMARKS_NUMBER):\n",
        "          for dimension in range(LANDMARK_DIMENSION):\n",
        "            X[video_id][frame][landmark][dimension] = landmarks[landmark][dimension]\n",
        "    \n",
        "    # Mise à jour de y avec le numéro de la vidéo, l'id du geste, le début du geste et la fin du geste\n",
        "    infos_y = np.array([video_id, gesture_id, t_start, t_end-1])\n",
        "    y = np.append(y, infos_y[np.newaxis, :], axis=0)\n",
        "  \n",
        "  # Affichage des shapes des résultats\n",
        "  print(\"\\rDataset continu - \" + annotations_file_path)\n",
        "  print(\"Shape X :\", X.shape)\n",
        "  print(\"Shape y :\", y.shape, \"\\n\")\n",
        "  \n",
        "  return X, y"
      ],
      "metadata": {
        "id": "l2TWTo4xM6-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_segmented, y_train_segmented = create_segmented_dataset(\"Annot_TrainList.txt\")\n",
        "X_test_segmented, y_test_segmented = create_segmented_dataset(\"Annot_TestList.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkMU5QO1zlsE",
        "outputId": "5b0413e4-282e-4b7e-ebee-35d52db01b6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset segmenté - Annot_TrainList.txt\n",
            "X shape : (4039, 970, 21, 3)\n",
            "Y shape : (4039,) \n",
            "\n",
            "Dataset segmenté - Annot_TestList.txt\n",
            "X shape : (1610, 667, 21, 3)\n",
            "Y shape : (1610,) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_continuous, y_train_continuous = create_continuous_dataset(\"Annot_TrainList.txt\")\n",
        "X_test_continuous, y_test_continuous = create_continuous_dataset(\"Annot_TestList.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSTJI6fOSWD7",
        "outputId": "3b6f4e64-8cd7-4652-cfdb-943e7237e6f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset continu - Annot_TrainList.txt\n",
            "Shape X : (148, 4905, 21, 3)\n",
            "Shape y : (4039, 4) \n",
            "\n",
            "Dataset continu - Annot_TestList.txt\n",
            "Shape X : (52, 5038, 21, 3)\n",
            "Shape y : (1610, 4) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Vidéo, Geste, Start, End\")\n",
        "print(y_train_continuous[:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KamM7ijZUPip",
        "outputId": "24d25c17-d4b7-4d68-9b18-bc0aacaf4a95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vidéo, Geste, Start, End\n",
            "[[   0    0    0   16]\n",
            " [   0   13   17   54]\n",
            " [   0    2   55  283]\n",
            " [   0    6  284  307]\n",
            " [   0    2  308  501]\n",
            " [   0    7  502  543]\n",
            " [   0    2  544  856]\n",
            " [   0    5  857  898]\n",
            " [   0    1  899 1121]\n",
            " [   0    0 1122 1431]\n",
            " [   0    4 1432 1456]\n",
            " [   0    1 1457 1706]\n",
            " [   0    0 1707 2041]\n",
            " [   0   10 2042 2076]\n",
            " [   0    1 2077 2349]\n",
            " [   0    8 2350 2390]\n",
            " [   0    2 2391 2602]\n",
            " [   0   12 2603 2645]\n",
            " [   0    2 2646 2793]\n",
            " [   0    0 2794 2992]\n",
            " [   0   11 2993 3028]\n",
            " [   0    1 3029 3231]\n",
            " [   0    9 3232 3276]\n",
            " [   0    1 3277 3644]\n",
            " [   0    3 3645 3675]\n",
            " [   0    0 3676 3750]\n",
            " [   1    0    0   23]\n",
            " [   1   12   24   64]\n",
            " [   1    2   65  346]\n",
            " [   1   13  347  380]]\n"
          ]
        }
      ]
    }
  ]
}